{"version":3,"sources":["PitchProcessor.worklet.ts","PitchNode.ts","setupAudio.ts","App.tsx","README.md","reportWebVitals.ts","index.tsx"],"names":["module","exports","PitchNode","onPitchDetectedCallback","numAudioSamplesPerAnalysis","onprocessorerror","err","console","log","wasmBytes","this","port","onmessage","event","data","postMessage","type","sampleRate","context","pitch","AudioWorkletNode","getWebAudioMediaStream","a","window","navigator","mediaDevices","Error","getUserMedia","audio","video","result","name","setupAudio","mediaStream","AudioContext","resume","audioSource","createMediaStreamSource","fetch","response","arrayBuffer","audioWorklet","addModule","PitchProcessorUrl","message","node","init","connect","destination","PitchReadout","running","latestPitch","className","toFixed","AudioRecorderControl","React","useState","undefined","setAudio","setRunning","setLatestPitch","onClick","suspend","state","disabled","App","reportWebVitals","onPerfEntry","Function","then","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"sIAAAA,EAAOC,QAAU,IAA0B,mC,4NCItBC,E,4MAEZC,wBAAmD,a,EACnDC,2BAA4C,K,EAkBnDC,iBAAmB,SAACC,GAClBC,QAAQC,IAAR,gEAAqEF,K,0CAdvE,SAAKG,EAAwBN,EAAkDC,GAAqC,IAAD,OACjHM,KAAKP,wBAA0BA,EAC/BO,KAAKN,2BAA6BA,EAGlCM,KAAKC,KAAKC,UAAY,SAAAC,GAAK,OAAI,EAAKD,UAAUC,EAAMC,OACpDJ,KAAKC,KAAKI,YAAY,CACpBC,KAAM,mBACNP,gB,uBASJ,SAAUI,GACW,uBAAfA,EAAMG,KAGRN,KAAKC,KAAKI,YAAY,CACpBC,KAAM,gBACNC,WAAYP,KAAKQ,QAAQD,WACzBb,2BAA4BM,KAAKN,6BAEX,UAAfS,EAAMG,MAAoBH,EAAMM,OAEzCT,KAAKP,wBAAwBU,EAAMM,W,eApCFC,mB,SCAxBC,I,2EAAf,4BAAAC,EAAA,yDACOC,OAAOC,UAAUC,aADxB,sBAEU,IAAIC,MACR,qFAHN,gCAQyBH,OAAOC,UAAUC,aAAaE,aAAa,CAC9DC,OAAO,EACPC,OAAO,IAVb,cAQUC,EARV,yBAaWA,GAbX,qCAeY,KAAEC,KAfd,OAgBW,oBAhBX,QAoBW,kBApBX,+BAiBc,IAAIL,MACR,oHAlBV,cAqBc,IAAIA,MACR,oEAtBV,6E,sBA8BO,SAAeM,EAAtB,kC,4CAAO,WAA0B7B,GAA1B,yBAAAmB,EAAA,sEAEqBD,IAFrB,cAECY,EAFD,OAGCf,EAAU,IAAIK,OAAOW,aAHtB,SAIChB,EAAQiB,SAJT,cAKCC,EAAclB,EAAQmB,wBAAwBJ,GAL/C,mBAWoBV,OAAOe,MAAM,iCAXjC,eAWGC,EAXH,iBAYqBA,EAASC,cAZ9B,eAYG/B,EAZH,2BAgBKS,EAAQuB,aAAaC,UAAUC,KAhBpC,iEAkBK,IAAIjB,MAAJ,wDAC6CiB,IAD7C,sBAC4E,KAAEC,UAnBnF,QAsBHrC,QAAQC,IAAI,8BAEZD,QAAQC,IAAIU,EAAShB,GACrB2C,EAAO,IAAI3C,EAAUgB,EAAS,kBAC9BX,QAAQC,IAAI,oCACuB,KAEnCqC,EAAKC,KAAKrC,EAAWN,EAFc,MAGnCI,QAAQC,IAAI,eACZ4B,EAAYW,QAAQF,GACpBtC,QAAQC,IAAI,4BACZqC,EAAKE,QAAQ7B,EAAQ8B,aACrBzC,QAAQC,IAAI,iCAlCT,wDAoCG,IAAIkB,MAAJ,mEACwD,KAAIkB,UArC/D,iCAyCE,CAAE1B,UAAS2B,SAzCb,mE,yCC1BP,SAASI,EAAT,GAA2F,IAApEC,EAAmE,EAAnEA,QAASC,EAA0D,EAA1DA,YAC9B,OACE,qBAAKC,UAAW,gBAAhB,SACGD,EAAW,wBACSA,EAAYE,QAAQ,GAD7B,OAERH,EACA,eACA,WAMV,SAASI,IAAwB,IAAD,EACJC,IAAMC,cAAkEC,GADpE,mBACvB7B,EADuB,KAChB8B,EADgB,OAEAH,IAAMC,UAAkB,GAFxB,mBAEvBN,EAFuB,KAEdS,EAFc,OAGQJ,IAAMC,cAA6BC,GAH3C,mBAGvBN,EAHuB,KAGVS,EAHU,KAK9B,IAAKhC,EACH,OACE,wBACEiC,QAAO,sBAAE,sBAAAvC,EAAA,kEACPoC,EADO,SACQ1B,EAAW4B,GADnB,kCAEPD,GAAW,GAFJ,2CADX,mBAP0B,IAmBtBzC,EAAYU,EAAZV,QACR,OACE,gCACE,cAAC+B,EAAD,CAAcC,QAASA,EAASC,YAAaA,IAC7C,wBACEU,QAAO,sBAAE,sBAAAvC,EAAA,0DACH4B,EADG,gCAEChC,EAAQ4C,UAFT,OAGLH,EAA6B,YAAlBzC,EAAQ6C,OAHd,sCAKC7C,EAAQiB,SALT,OAMLwB,EAA6B,YAAlBzC,EAAQ6C,OANd,2CASTC,SAA4B,YAAlB9C,EAAQ6C,OAAyC,cAAlB7C,EAAQ6C,MAVnD,SAYGb,EAAU,QAAU,cA4Bde,MAtBf,WACE,OACE,qBAAKb,UAAU,MAAf,SACE,sBAAKA,UAAU,WAAf,UACE,qBAAKA,UAAU,eAAf,SACE,qBAAKA,UAAU,oBAAf,SACE,cAAC,IAAD,UCpEG,w0HDuEP,sBAAKA,UAAU,iBAAf,UACE,wBAAQA,UAAU,cAAlB,mBAGA,qBAAKA,UAAU,eAAf,SACE,cAACE,EAAD,eE9DGY,EAZS,SAACC,GACnBA,GAAeA,aAAuBC,UACxC,6BAAqBC,MAAK,YAAkD,IAA/CC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAON,GACPO,EAAQP,OCHdQ,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,SAM1Bb,M","file":"static/js/main.cf4c075e.chunk.js","sourcesContent":["module.exports = __webpack_public_path__ + \"b2992b298ba9f157c00b.worklet.js\";","interface PitchMessageEvent extends MessageEvent {\r\n  pitch?: number\r\n}\r\n\r\nexport default class PitchNode extends AudioWorkletNode {\r\n\r\n  public onPitchDetectedCallback: (pitch: number) => void = () => {}\r\n  public numAudioSamplesPerAnalysis: number | null = null\r\n\r\n  // initialize PitchProcessor: send wasm code\r\n  // @param {ArrayBuffer} wasmBytes: wasm module code\r\n  // @param {number} numAudioSamplesPerAnalysis: analysis window. must be power of 2.\r\n  init(wasmBytes: ArrayBuffer, onPitchDetectedCallback: (pitch: number) => void, numAudioSamplesPerAnalysis: number) {\r\n    this.onPitchDetectedCallback = onPitchDetectedCallback\r\n    this.numAudioSamplesPerAnalysis = numAudioSamplesPerAnalysis;\r\n\r\n    // Listen to messages sent from the audioProcessor\r\n    this.port.onmessage = event => this.onmessage(event.data);\r\n    this.port.postMessage({\r\n      type: \"send-wasm-module\",\r\n      wasmBytes\r\n    })\r\n  }\r\n\r\n  // Handle an uncaught exception thrown in the PitchProcessor\r\n  onprocessorerror = (err: Event) => {\r\n    console.log(`An error occurred in AudioWorkletProcessor.process(): ${err}`)\r\n  }\r\n\r\n  onmessage(event: PitchMessageEvent) {\r\n    if (event.type === 'wasm-module-loaded') {\r\n      // This message means wasm was loaded and compiled.\r\n      // Now we send one back to configure the pitch detector.\r\n      this.port.postMessage({\r\n        type: 'init-detector',\r\n        sampleRate: this.context.sampleRate,\r\n        numAudioSamplesPerAnalysis: this.numAudioSamplesPerAnalysis\r\n      });\r\n    } else if (event.type === 'pitch' && event.pitch) {\r\n      // A pitch was detected, so invoke our callback to update the UI.\r\n      this.onPitchDetectedCallback(event.pitch);\r\n    }\r\n  }\r\n\r\n}","// eslint-disable-next-line import/no-webpack-loader-syntax\r\nimport PitchProcessorUrl from 'worklet-loader!./PitchProcessor.worklet.ts';\r\nimport PitchNode from './PitchNode'\r\n\r\nasync function getWebAudioMediaStream() {\r\n  if (!window.navigator.mediaDevices) {\r\n    throw new Error(\r\n      \"This browser doesn't support the Web Audio API, or the Web Audio API is disabled.\"\r\n    )\r\n  }\r\n\r\n  try {\r\n    const result = await window.navigator.mediaDevices.getUserMedia({\r\n      audio: true,\r\n      video: false\r\n    })\r\n\r\n    return result;\r\n  } catch (e) {\r\n    switch (e.name) {\r\n      case \"NotAllowedError\":\r\n        throw new Error(\r\n          \"A recording device was found but the application couldn't access it. Enable the device in your browser settings.\"\r\n        );\r\n      case \"NotFoundError\":\r\n        throw new Error(\r\n          \"No recording device found. Plug in a microphone and click retry.\"\r\n        )\r\n      default:\r\n        throw e\r\n    }\r\n  }\r\n}\r\n\r\nexport async function setupAudio(onPitchDetectedCallback: (pitch: number) => void) {\r\n  // get browser audio\r\n  const mediaStream = await getWebAudioMediaStream();\r\n  const context = new window.AudioContext();\r\n  await context.resume()\r\n  const audioSource = context.createMediaStreamSource(mediaStream);\r\n\r\n  let node;\r\n\r\n  try {\r\n    // Fetch WASM code\r\n    const response = await window.fetch(\"wasm-tuner/wasm_tuner_bg.wasm\");\r\n    const wasmBytes = await response.arrayBuffer();\r\n\r\n    // Add our worklet to the context\r\n    try {\r\n      await context.audioWorklet.addModule(PitchProcessorUrl);\r\n    } catch (e) {\r\n      throw new Error(\r\n        `Failed to load audio analyzer worklet at url: ${PitchProcessorUrl}. Details: ${e.message}`\r\n      )\r\n    }\r\n    console.log('loaded module into worklet')\r\n    // create the worklet node\r\n    console.log(context, PitchNode)\r\n    node = new PitchNode(context, \"PitchProcessor\")\r\n    console.log('loaded module into audio context')\r\n    const numAudioSamplesPerAnalysis = 1024\r\n\r\n    node.init(wasmBytes, onPitchDetectedCallback, numAudioSamplesPerAnalysis);\r\n    console.log('called init')\r\n    audioSource.connect(node)\r\n    console.log('connected source to node')\r\n    node.connect(context.destination)\r\n    console.log('connected node to destination')\r\n  } catch (err) {\r\n    throw new Error(\r\n      `Failed to load audio analyzer WASM module. Further info: ${err.message}`\r\n    );\r\n  }\r\n\r\n  return { context, node };\r\n}","import React from 'react';\nimport './App.css';\nimport { setupAudio } from './setupAudio';\nimport PitchNode from './PitchNode';\nimport Markdown from 'react-markdown';\n// eslint-disable-next-line import/no-webpack-loader-syntax\nimport README from '!raw-loader!./README.md';\n\nfunction PitchReadout({running, latestPitch}: { running: boolean, latestPitch?: number }) {\n  return (\n    <div className={\"Pitch-readout\"}>\n      {latestPitch\n        ? `Latest pitch: ${latestPitch.toFixed(1)} Hz`\n        : running\n        ? \"Listening...\"\n        : \"Paused\"\n      }\n    </div>\n  )\n}\n\nfunction AudioRecorderControl() {\n  const [audio, setAudio] = React.useState<{ context:  AudioContext, node: PitchNode } | undefined>(undefined)\n  const [running, setRunning] = React.useState<boolean>(false)\n  const [latestPitch, setLatestPitch] = React.useState<number | undefined>(undefined)\n\n  if (!audio) {\n    return (\n      <button\n        onClick={async () => {\n          setAudio(await setupAudio(setLatestPitch));\n          setRunning(true);\n        }}\n      >\n        Start\n      </button>\n    )\n  }\n\n  // otherwise, audio already initialized\n  const { context } = audio;\n  return (\n    <div>\n      <PitchReadout running={running} latestPitch={latestPitch} />\n      <button\n        onClick={async () => {\n          if (running) {\n            await context.suspend();\n            setRunning(context.state === 'running')\n          } else {\n            await context.resume();\n            setRunning(context.state === 'running')\n          }\n        }}\n        disabled={context.state !== 'running' && context.state !== 'suspended'}\n      >\n        {running ? \"Pause\" : \"Resume\"}\n      </button>\n    </div>\n  )\n}\n\nfunction App() {\n  return (\n    <div className=\"App\">\n      <div className='appInner'>\n        <div className='markdownPane'>\n          <div className='markdownContainer'>\n            <Markdown>{README}</Markdown>\n          </div>\n        </div>\n        <div className='tunerContainer'>\n          <header className=\"tunerHeader\">\n                Tuner\n          </header>\n          <div className=\"tunerContent\">\n            <AudioRecorderControl />\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n\nexport default App;\n","export default \"## TypeScript / Rust Audio Worklet example with Firefox support\\n### Based on [Peter Suggate's JS walkthrough](https://www.toptal.com/webassembly/webassembly-rust-tutorial-web-audio)\\n#### \\n#### by [Tim Fitzgerald](https://github.com/timfitzzz) -- [source](https://github.com/timfitzzz/wasm-rust-worklet-typescript)\\n\\nFirst, everybody interested in getting started building Web Audio nodes with WASM and Audio Worklet should go visit [Peter Suggate](https://www.toptal.com/resume/peter-suggate)'s awesome walkthrough of how to use Rust, WebAssembly, and JavaScript to create custom Web Audio nodes, [\\\"WebAssembly/Rust Tutorial: Pitch-perfect Audio Processing\\\"](https://www.toptal.com/webassembly/webassembly-rust-tutorial-web-audio). Provided therein is a full walkthrough of how to create a JavaScript version of this example. \\n\\nAs a practice exercise, I rewrote the example code in TypeScript, including the JS code meant to run in the second, Audio Worklet thread. This introduced some new issues, particularly when I tried to use tsc to compile the worker code into the static /public folder in which the JS implementation had been placed by Suggate: to load the compiled TypeScript code as a module of the types supported by both TSC and the browser, we'd need to import additional modules (like RequireJS), which can't be done within the code being loaded as a module! Additionally, as Suggate notes, Firefox doesn't support *any* type of importing at all from within the worker thread, something that entirely prevented his implementation from supporting that browser.\\n\\nUltimately, both problems had the same solution: the best way I found to get compiled TypeScript code running inside the Worklet thread was to rely on Webpack and the [worklet-loader](https://github.com/reklawnos/worklet-loader) plugin, which allowed me to bundle the (JS) Worklet code into a blob that then could be loaded into the Web Audio context, without needing to precompile it into the /public folder at all.\\n\\nApparently, worklet-loader is not meant to be relied upon as a production solution, underscoring the somewhat prototypical state of the entire Audio Worklet ecosystem. The Web Audio API is an extremely competent interface for handling the most common audio needs of front-end developers, but when it comes to some of the more adventurous potential uses, it can sometimes be difficult to find strong examples from which to draw inspiration. I hope you find this boilerplate a useful contribution, and again, please [give a click to Peter Suggate for his great and helpful walkthrough](https://www.toptal.com/webassembly/webassembly-rust-tutorial-web-audio).\\n\\n## Changes From Suggate Tutorial\\n\\n### Include copy of wasm-pack output in /src folder\\n\\nWhile we'll still need to load the .wasm file provided by wasm-pack from the /public folder, we'll use the binding file it generates directly within our application code. So make sure to copy wasm-tuner/wasm_tuner.js into your /src folder as well.\\n\\n### Add worklet-loader and text-encoding to your project\\n\\n```\\nyarn add worklet-loader text-encoding\\n```\\n\\n### Modify wasm-pack-generated json binding file\\n\\nIn ```/src/wasm-tuner/wasm_tuner.js```, import the TextEncoder.js file directly on line 1:\\n\\n```\\nconst { TextEncoder, TextDecoder } = require('text-encoding');\\n```\\n\\nAnd on line 203, replace the reference to ```input.meta.url``` to the Webpack-specific variable, __webpack_public_path__:\\n\\n```\\ninput = new URL('wasm_tuner_bg.wasm', __webpack_public_path__);\\n```\\n\\n### In setupAudio.ts, import your worklet processor using worklet-loader:\\n\\n```\\nimport PitchProcessorUrl from 'worklet-loader!./PitchProcessor.worklet.ts';\\n```\\n\\n### Finally, when you add the module to the audio worklet context, just use the PitchProcessorUrl generated by worker-loader:\\n\\n```\\nawait context.audioWorklet.addModule(PitchProcessorUrl);\\n```\";","import { ReportHandler } from 'web-vitals';\n\nconst reportWebVitals = (onPerfEntry?: ReportHandler) => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}