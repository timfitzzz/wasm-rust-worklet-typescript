(this["webpackJsonpwasm-rust-worklet-typescript"]=this["webpackJsonpwasm-rust-worklet-typescript"]||[]).push([[0],{21:function(e,t,n){e.exports=n.p+"b2992b298ba9f157c00b.worklet.js"},35:function(e,t,n){},37:function(e,t,n){},43:function(e,t,n){"use strict";n.r(t);var o=n(2),r=n.n(o),a=n(23),i=n.n(a),s=(n(35),n(4)),c=n.n(s),l=n(10),u=n(19),d=(n(37),n(21)),p=n.n(d),h=n(3),w=n(16),m=n(7),b=n(9),g=n(18),f=function(e){Object(m.a)(n,e);var t=Object(b.a)(n);function n(){var e;Object(h.a)(this,n);for(var o=arguments.length,r=new Array(o),a=0;a<o;a++)r[a]=arguments[a];return(e=t.call.apply(t,[this].concat(r))).onPitchDetectedCallback=function(){},e.numAudioSamplesPerAnalysis=null,e.onprocessorerror=function(e){console.log("An error occurred in AudioWorkletProcessor.process(): ".concat(e))},e}return Object(w.a)(n,[{key:"init",value:function(e,t,n){var o=this;this.onPitchDetectedCallback=t,this.numAudioSamplesPerAnalysis=n,this.port.onmessage=function(e){return o.onmessage(e.data)},this.port.postMessage({type:"send-wasm-module",wasmBytes:e})}},{key:"onmessage",value:function(e){"wasm-module-loaded"===e.type?this.port.postMessage({type:"init-detector",sampleRate:this.context.sampleRate,numAudioSamplesPerAnalysis:this.numAudioSamplesPerAnalysis}):"pitch"===e.type&&e.pitch&&this.onPitchDetectedCallback(e.pitch)}}]),n}(Object(g.a)(AudioWorkletNode));function y(){return k.apply(this,arguments)}function k(){return(k=Object(l.a)(c.a.mark((function e(){var t;return c.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:if(window.navigator.mediaDevices){e.next=2;break}throw new Error("This browser doesn't support the Web Audio API, or the Web Audio API is disabled.");case 2:return e.prev=2,e.next=5,window.navigator.mediaDevices.getUserMedia({audio:!0,video:!1});case 5:return t=e.sent,e.abrupt("return",t);case 9:e.prev=9,e.t0=e.catch(2),e.t1=e.t0.name,e.next="NotAllowedError"===e.t1?14:"NotFoundError"===e.t1?15:16;break;case 14:throw new Error("A recording device was found but the application couldn't access it. Enable the device in your browser settings.");case 15:throw new Error("No recording device found. Plug in a microphone and click retry.");case 16:throw e.t0;case 17:case"end":return e.stop()}}),e,null,[[2,9]])})))).apply(this,arguments)}function x(e){return v.apply(this,arguments)}function v(){return(v=Object(l.a)(c.a.mark((function e(t){var n,o,r,a,i,s;return c.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:return e.next=2,y();case 2:return n=e.sent,o=new window.AudioContext,e.next=6,o.resume();case 6:return r=o.createMediaStreamSource(n),e.prev=7,e.next=10,window.fetch("wasm-tuner/wasm_tuner_bg.wasm");case 10:return i=e.sent,e.next=13,i.arrayBuffer();case 13:return s=e.sent,e.prev=14,e.next=17,o.audioWorklet.addModule(p.a);case 17:e.next=22;break;case 19:throw e.prev=19,e.t0=e.catch(14),new Error("Failed to load audio analyzer worklet at url: ".concat(p.a,". Details: ").concat(e.t0.message));case 22:console.log("loaded module into worklet"),console.log(o,f),a=new f(o,"PitchProcessor"),console.log("loaded module into audio context"),1024,a.init(s,t,1024),console.log("called init"),r.connect(a),console.log("connected source to node"),a.connect(o.destination),console.log("connected node to destination"),e.next=38;break;case 35:throw e.prev=35,e.t1=e.catch(7),new Error("Failed to load audio analyzer WASM module. Further info: ".concat(e.t1.message));case 38:return e.abrupt("return",{context:o,node:a});case 39:case"end":return e.stop()}}),e,null,[[7,35],[14,19]])})))).apply(this,arguments)}var j=n(28),A=n(1);function P(e){var t=e.running,n=e.latestPitch;return Object(A.jsx)("div",{className:"Pitch-readout",children:n?"Latest pitch: ".concat(n.toFixed(1)," Hz"):t?"Listening...":"Paused"})}function S(){var e=r.a.useState(void 0),t=Object(u.a)(e,2),n=t[0],o=t[1],a=r.a.useState(!1),i=Object(u.a)(a,2),s=i[0],d=i[1],p=r.a.useState(void 0),h=Object(u.a)(p,2),w=h[0],m=h[1];if(!n)return Object(A.jsx)("button",{onClick:Object(l.a)(c.a.mark((function e(){return c.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:return e.t0=o,e.next=3,x(m);case 3:e.t1=e.sent,(0,e.t0)(e.t1),d(!0);case 6:case"end":return e.stop()}}),e)}))),children:"Start"});var b=n.context;return Object(A.jsxs)("div",{children:[Object(A.jsx)(P,{running:s,latestPitch:w}),Object(A.jsx)("button",{onClick:Object(l.a)(c.a.mark((function e(){return c.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:if(!s){e.next=6;break}return e.next=3,b.suspend();case 3:d("running"===b.state),e.next=9;break;case 6:return e.next=8,b.resume();case 8:d("running"===b.state);case 9:case"end":return e.stop()}}),e)}))),disabled:"running"!==b.state&&"suspended"!==b.state,children:s?"Pause":"Resume"})]})}var O=function(){return Object(A.jsx)("div",{className:"App",children:Object(A.jsxs)("div",{className:"appInner",children:[Object(A.jsx)("div",{className:"markdownPane",children:Object(A.jsx)("div",{className:"markdownContainer",children:Object(A.jsx)(j.a,{children:"## TypeScript / Rust Audio Worklet example with Firefox support\n### Based on [Peter Suggate's JS walkthrough](https://www.toptal.com/webassembly/webassembly-rust-tutorial-web-audio)\n#### \n#### by [Tim Fitzgerald](https://github.com/timfitzzz) -- [source](https://github.com/timfitzzz/wasm-rust-worklet-typescript)\n\nFirst, everybody interested in getting started building Web Audio nodes with WASM and Audio Worklet should go visit [Peter Suggate](https://www.toptal.com/resume/peter-suggate)'s awesome walkthrough of how to use Rust, WebAssembly, and JavaScript to create custom Web Audio nodes, [\"WebAssembly/Rust Tutorial: Pitch-perfect Audio Processing\"](https://www.toptal.com/webassembly/webassembly-rust-tutorial-web-audio). Provided therein is a full walkthrough of how to create a JavaScript version of this example. \n\nAs a practice exercise, I rewrote the example code in TypeScript, including the JS code meant to run in the second, Audio Worklet thread. This introduced some new issues, particularly when I tried to use tsc to compile the worker code into the static /public folder in which the JS implementation had been placed by Suggate: to load the compiled TypeScript code as a module of the types supported by both TSC and the browser, we'd need to import additional modules (like RequireJS), which can't be done within the code being loaded as a module! Additionally, as Suggate notes, Firefox doesn't support *any* type of importing at all from within the worker thread, something that entirely prevented his implementation from supporting that browser.\n\nUltimately, both problems had the same solution: the best way I found to get compiled TypeScript code running inside the Worklet thread was to rely on Webpack and the [worklet-loader](https://github.com/reklawnos/worklet-loader) plugin, which allowed me to bundle the (JS) Worklet code into a blob that then could be loaded into the Web Audio context, without needing to precompile it into the /public folder at all.\n\nApparently, worklet-loader is not meant to be relied upon as a production solution, underscoring the somewhat prototypical state of the entire Audio Worklet ecosystem. The Web Audio API is an extremely competent interface for handling the most common audio needs of front-end developers, but when it comes to some of the more adventurous potential uses, it can sometimes be difficult to find strong examples from which to draw inspiration. I hope you find this boilerplate a useful contribution, and again, please [give a click to Peter Suggate for his great and helpful walkthrough](https://www.toptal.com/webassembly/webassembly-rust-tutorial-web-audio).\n\n## Changes From Suggate Tutorial\n\n### Include copy of wasm-pack output in /src folder\n\nWhile we'll still need to load the .wasm file provided by wasm-pack from the /public folder, we'll use the binding file it generates directly within our application code. So make sure to copy wasm-tuner/wasm_tuner.js into your /src folder as well.\n\n### Add worklet-loader and text-encoding to your project\n\n```\nyarn add worklet-loader text-encoding\n```\n\n### Modify wasm-pack-generated json binding file\n\nIn ```/src/wasm-tuner/wasm_tuner.js```, import the TextEncoder.js file directly on line 1:\n\n```\nconst { TextEncoder, TextDecoder } = require('text-encoding');\n```\n\nAnd on line 203, replace the reference to ```input.meta.url``` to the Webpack-specific variable, __webpack_public_path__:\n\n```\ninput = new URL('wasm_tuner_bg.wasm', __webpack_public_path__);\n```\n\n### In setupAudio.ts, import your worklet processor using worklet-loader:\n\n```\nimport PitchProcessorUrl from 'worklet-loader!./PitchProcessor.worklet.ts';\n```\n\n### Finally, when you add the module to the audio worklet context, just use the PitchProcessorUrl generated by worker-loader:\n\n```\nawait context.audioWorklet.addModule(PitchProcessorUrl);\n```"})})}),Object(A.jsxs)("div",{className:"tunerContainer",children:[Object(A.jsx)("header",{className:"tunerHeader",children:"Tuner"}),Object(A.jsx)("div",{className:"tunerContent",children:Object(A.jsx)(S,{})})]})]})})},W=function(e){e&&e instanceof Function&&n.e(3).then(n.bind(null,47)).then((function(t){var n=t.getCLS,o=t.getFID,r=t.getFCP,a=t.getLCP,i=t.getTTFB;n(e),o(e),r(e),a(e),i(e)}))};i.a.render(Object(A.jsx)(r.a.StrictMode,{children:Object(A.jsx)(O,{})}),document.getElementById("root")),W()}},[[43,1,2]]]);
//# sourceMappingURL=main.cf4c075e.chunk.js.map